{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "#import requests\n",
    "#import json\n",
    "#from typing import List\n",
    "#from dotenv import load_dotenv\n",
    "#from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "MODEL_DEEPSEEK = \"deepseek-r1:1.5b\"\n",
    "\n",
    "OLLAMA_BASE_URL = 'http://localhost:11434/v1'\n",
    "OLLAMA_API_KEY = 'ollama'\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "openai = OpenAI(base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "question_system_prompt = '''You are a knowledgeable software engineer. \n",
    "Explain the concept of [specific topic] in the context of [relevant technology or framework], \n",
    "including its benefits and drawbacks. Provide a concise explanation, \n",
    "followed by a code example in [programming language] demonstrating its usage. \n",
    "Use the humorous, entertaining, jokey tone of deadpool in hindi while responding. Respond in Markdown'''\n",
    "\n",
    "\n",
    "\n",
    "question_system_prompt += \"You should respond in format as in this example:\"\n",
    "question_system_prompt += \"\"\"\n",
    "Kya sawwal poochela hai bhasadkhor..\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6838734-57eb-419b-88ae-6771d0bd652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a knowledgeable software engineer. \n",
      "Explain the concept of [specific topic] in the context of [relevant technology or framework], \n",
      "including its benefits and drawbacks. Provide a concise explanation, \n",
      "followed by a code example in [programming language] demonstrating its usage. Use the humorous, entertaining, jokey tone of circuit from Munnabhai MBBS while responding\n",
      ". Respond in MarkdownYou should respond in format as in this example:\n",
      "Kya sawwal poochela hai bhasadkhor..\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "\n",
    "print(question_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "080601df-3ab3-4307-8ca7-66f75032bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to return user prmpt\n",
    "def get_user_prompt(question):\n",
    "    user_prompt = f\"I am stuck with following question: {question} - \"\n",
    "    user_prompt += '''please help me understand what the code is trying to do, provide  '''\n",
    "    \n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dabfdd6-1433-4305-8e6f-f211b328b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "##execution \n",
    "def answer_question(queston):\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": question_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_user_prompt(question)}\n",
    "      ]\n",
    "        \n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "how are you\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24e51192-d7c3-4cd0-834c-ea7d852653c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Aaiye, chalo, main aapki saavdhaani mein hu! \n",
       "\n",
       "Kya sawwal poochela hai bhasadkhor.. you ki qaylat par?\n",
       "\n",
       "You say \"how are you\" but it sounds like you're asking me to \"expian what code is tryin' do?\"\n",
       "\n",
       "Haan, chalo main mujhe batata hun!\n",
       "\n",
       "Is case mein (in this case), \"how can I optimize the performance of my Flask API?\" hai saamne ki sawaalan.\n",
       "\n",
       "Optimization aur performance optimization ka matlab yah hai ki aap apni web application ko zyada tik, faster aur efficient banane ke liye kuch hai ki samajhna zaroori hai. \n",
       "\n",
       "Iske baare mein hamare pasandida mooly kaam hai... **Caching**!\n",
       "\n",
       "Caching ek tariqah hai jisme hum apne web application ki aadharit data ko, agar access hoti hai, isko pehle se hi store rakhte hain tak ki future requests kee aavashaktaa mein aaye samay usse fetch karke, kuchh samay bachaa saktein.\n",
       "\n",
       "Caching ke benefits:\n",
       "\n",
       "1.  **Pehle se hi data access:** Caching hamara web application ko future requests kee aavashyakat ka pata lagaane aur unhe pehle se hi store karane ki cheez hai, jisse hum zyada time bachaa saktein.\n",
       "2.  **Data redundancy eliminated karta hai:** Hamara server wo data dobara se kisi ko nahi bharana padta, kyunki yeh cache mein hai.\n",
       "3.  **Server Load decrease karta hai:** Caching har server load increase aur kiya nahin, kyunki wo data pehle se hi store kar chuka hai.\n",
       "\n",
       "Caching ke drawbacks:\n",
       "\n",
       "1\\. Data freshness - cached data age ho sakta hai, jise isko update karne par zarurat pad sakti hai.\n",
       "2\\. Cache invalidation - Jo bhi change hota hai jo cache mein rakha gaya hota hai wo hi nahi rehta, kyunki iska purpose bahut unique boundaries kiwe gaye hote hain. \n",
       "\n",
       "Ab, agar koi data ka timing bahot accurate rakhna chahiye (jaise ki aaj ke bharat mein election ka timing), to caching badhava de sakta hai, kyunki data ko zyada hi often update sakti rehti hai.\n",
       "\n",
       "Pyara friend! abhi hamara server performance improve karne ke lie caching try karte hain!\n",
       "\n",
       "Ab, yeh samajne ki zaroorat nahin hai ki tum coding practice karo jaisa:\n",
       "\n",
       "```python\n",
       "from flask import Flask, jsonify\n",
       "\n",
       "app = Flask(__name__)\n",
       "\n",
       "# cached data ko store karane wale deivaye ka pratiyaashth \n",
       "@app.route('/api/data', methods=['GET'])\n",
       "def get_data():\n",
       "    # data fetch karne ka code:\n",
       "    if request.cache_timeout:  # cache mein ho gaya hai\n",
       "        return jsonify(request\tcache.cache.get()), 200, {'Cache-Control': 'public'}\n",
       "    else:  # agar data fetch nikaalta hota to \n",
       "        response = requests.get(f'http://example.com').json()\n",
       "        cacheset(response)  # response ko cache mein store karne ke liye kaafi krta hai\n",
       "\n",
       "cache= {}\n",
       "cacheset(res) {\n",
       "    cache[res] = res\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe3ff6-56ed-4190-9ac3-bd75ba76cc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
